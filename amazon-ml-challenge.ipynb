{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9386268,"sourceType":"datasetVersion","datasetId":5695022},{"sourceId":9396815,"sourceType":"datasetVersion","datasetId":5703319}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-09-15T16:50:07.994402Z","iopub.execute_input":"2024-09-15T16:50:07.994839Z","iopub.status.idle":"2024-09-15T16:50:08.034362Z","shell.execute_reply.started":"2024-09-15T16:50:07.994796Z","shell.execute_reply":"2024-09-15T16:50:08.033218Z"},"trusted":true},"execution_count":203,"outputs":[{"name":"stdout","text":"/kaggle/input/vamshi/711pAe-vJhL.jpg\n/kaggle/input/processed-data/processed.csv.csv\n/kaggle/input/dataset/711gPYqqqIL.jpg\n/kaggle/input/dataset/71nywfWZUwL.jpg\n/kaggle/input/dataset/3.jpg\n/kaggle/input/dataset/51WsuKKAVrL.jpg\n/kaggle/input/newdataset/processed (10).csv\n/kaggle/input/testing3/21i52HRW4L.jpg\n/kaggle/input/images/1.jpg\n/kaggle/input/images/2.jpg\n/kaggle/input/testing2/test.csv\n/kaggle/input/amazon-dataset2/train.csv\n/kaggle/input/images21/61sQqAKr4L.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install tensorflow==2.15","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:50:08.304609Z","iopub.execute_input":"2024-09-15T16:50:08.305460Z","iopub.status.idle":"2024-09-15T16:50:18.936063Z","shell.execute_reply.started":"2024-09-15T16:50:08.305416Z","shell.execute_reply":"2024-09-15T16:50:18.934697Z"},"trusted":true},"execution_count":204,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tensorflow==2.15 in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (4.12.2)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (0.37.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (1.62.2)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.2)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15) (0.43.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.30.0)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.6)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.15) (3.1.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.1.5)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.6.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.2.2)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install keras_ocr","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:50:18.938540Z","iopub.execute_input":"2024-09-15T16:50:18.938928Z","iopub.status.idle":"2024-09-15T16:50:21.493120Z","shell.execute_reply.started":"2024-09-15T16:50:18.938891Z","shell.execute_reply":"2024-09-15T16:50:21.491709Z"},"trusted":true},"execution_count":205,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: keras_ocr in /opt/conda/lib/python3.10/site-packages (0.9.3)\nRequirement already satisfied: editdistance in /opt/conda/lib/python3.10/site-packages (from keras_ocr) (0.8.1)\nRequirement already satisfied: efficientnet==1.0.0 in /opt/conda/lib/python3.10/site-packages (from keras_ocr) (1.0.0)\nRequirement already satisfied: essential_generators in /opt/conda/lib/python3.10/site-packages (from keras_ocr) (1.0)\nRequirement already satisfied: fonttools in /opt/conda/lib/python3.10/site-packages (from keras_ocr) (4.53.0)\nRequirement already satisfied: imgaug in /opt/conda/lib/python3.10/site-packages (from keras_ocr) (0.4.0)\nRequirement already satisfied: pyclipper in /opt/conda/lib/python3.10/site-packages (from keras_ocr) (1.3.0.post5)\nRequirement already satisfied: shapely in /opt/conda/lib/python3.10/site-packages (from keras_ocr) (1.8.5.post1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from keras_ocr) (4.66.4)\nRequirement already satisfied: validators in /opt/conda/lib/python3.10/site-packages (from keras_ocr) (0.34.0)\nRequirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.10/site-packages (from efficientnet==1.0.0->keras_ocr) (1.0.8)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet==1.0.0->keras_ocr) (0.23.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from imgaug->keras_ocr) (1.16.0)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.10/site-packages (from imgaug->keras_ocr) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from imgaug->keras_ocr) (1.14.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from imgaug->keras_ocr) (9.5.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from imgaug->keras_ocr) (3.7.5)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from imgaug->keras_ocr) (4.10.0.84)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from imgaug->keras_ocr) (2.34.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras_ocr) (3.11.0)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (3.3)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (0.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug->keras_ocr) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug->keras_ocr) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug->keras_ocr) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug->keras_ocr) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug->keras_ocr) (2.9.0.post0)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install pytesseract","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:50:21.494902Z","iopub.execute_input":"2024-09-15T16:50:21.495281Z","iopub.status.idle":"2024-09-15T16:50:35.362919Z","shell.execute_reply.started":"2024-09-15T16:50:21.495244Z","shell.execute_reply":"2024-09-15T16:50:35.361491Z"},"trusted":true},"execution_count":206,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.13)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (21.3)\nRequirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->pytesseract) (3.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Ensuring TensorFlow uses GPU (default behavior)\nimport tensorflow as tf\n\n# Check if TensorFlow is using GPU\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Set memory growth to avoid full allocation of the GPU memory\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"GPU is available: {gpus}\")\n    except RuntimeError as e:\n        print(e)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:50:35.367075Z","iopub.execute_input":"2024-09-15T16:50:35.367636Z","iopub.status.idle":"2024-09-15T16:50:35.376098Z","shell.execute_reply.started":"2024-09-15T16:50:35.367594Z","shell.execute_reply":"2024-09-15T16:50:35.375008Z"},"trusted":true},"execution_count":207,"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\nGPU is available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Image Preprocessing**","metadata":{}},{"cell_type":"code","source":"import keras_ocr\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf  # For GPU support\nimport re\nimport cv2\nimport pytesseract\nfrom PIL import Image\nimport tempfile\n\n# Load the recognizer pipeline\npipeline = keras_ocr.pipeline.Pipeline(scale=50)\n\n# Function to detect text using keras-ocr\ndef detect_text_with_keras_ocr(image):\n    images = [image]\n    prediction_groups = pipeline.recognize(images)\n    return prediction_groups\n\n# Function to load and detect text using keras-ocr\ndef process_and_detect_text(image_path):\n    image = keras_ocr.tools.read(image_path)\n    prediction_groups = detect_text_with_keras_ocr(image)\n    return image, prediction_groups\n\n# Function for normalization of images\ndef normalize_image(image):\n    norm_img = np.zeros((image.shape[0], image.shape[1]))\n    image = cv2.normalize(image, norm_img, 0, 255, cv2.NORM_MINMAX)\n    return image\n\n# Function to remove noise from images\ndef remove_noise(image):\n    # Check if the image is grayscale (single channel)\n    if len(image.shape) == 2:  # Grayscale\n        return cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n    \n    elif len(image.shape) == 3:  # Colored\n        return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 15)\n    else:\n        raise ValueError(\"Unsupported image format for denoising\")\n\n# Main preprocessing function\ndef preprocess_image(image):\n    image = normalize_image(image)\n    gray = get_grayscale(image)\n    denoised = remove_noise(gray)  # Applies denoising based on image type\n    binary = thresholding(denoised)\n    upscaled_image = cv2.resize(binary, None, fx=6 ,fy=6, interpolation=cv2.INTER_CUBIC)\n    return upscaled_image\n\n\n# Function to convert image to grayscale\ndef get_grayscale(image):\n    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n# Function to threshold images\ndef thresholding(image):\n    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:51:54.832105Z","iopub.execute_input":"2024-09-15T16:51:54.833103Z","iopub.status.idle":"2024-09-15T16:51:58.197383Z","shell.execute_reply.started":"2024-09-15T16:51:54.833058Z","shell.execute_reply":"2024-09-15T16:51:58.196403Z"},"trusted":true},"execution_count":222,"outputs":[{"name":"stdout","text":"Looking for /root/.keras-ocr/craft_mlt_25k.h5\nLooking for /root/.keras-ocr/crnn_kurapan.h5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Weight","metadata":{}},{"cell_type":"code","source":"import re\nimport cv2\nimport numpy as np\nimport pytesseract\n\ndef find_and_crop_weight(image_path, keywords=None, non_weight_keywords=None):\n    # Default weight-related keywords\n    if keywords is None:\n        keywords = [\"kg\", \"gm\", \"g\", \"mg\", \"grams\", \"milligrams\", \"kilograms\", 'G', 'KG', 'Kg', 'pounds', 'oz','lb','lbs']\n    \n    # Default non-weight-related keywords\n    if non_weight_keywords is None:\n        non_weight_keywords = [\"mAh\", \"Ah\", \"A-h\", \"v\", \"W\"]\n\n    # Load the image and detect text boxes using your process_and_detect_text function\n    image, prediction_groups = process_and_detect_text(image_path)\n    cropped_images = []\n    cropped_texts = []\n\n    # Pattern to match a number followed by a weight unit\n    weight_pattern = re.compile(r'(?<!\\d)(\\d+\\.?\\d*)\\s*(' + r'|'.join(keywords) + r')(?!\\w)', re.IGNORECASE)\n    non_weight_pattern = re.compile(r'(?<!\\d)(\\d+\\.?\\d*)\\s*(' + r'|'.join(non_weight_keywords) + r')(?!\\w)', re.IGNORECASE)\n\n    # Merge text boxes that are close to each other\n    merged_text_boxes = []\n    merged_box = None\n    for i, (text, box) in enumerate(prediction_groups[0]):\n        box = np.int0(box)\n        x_min, y_min = np.min(box[:, 0]), np.min(box[:, 1])\n        x_max, y_max = np.max(box[:, 0]), np.max(box[:, 1])\n\n        if merged_box is None:\n            merged_box = {\"text\": text, \"x_min\": x_min, \"y_min\": y_min, \"x_max\": x_max, \"y_max\": y_max}\n        else:\n            # Check if the current box is close to the previous box (both horizontally and vertically)\n            if x_min - merged_box[\"x_max\"] < 19 and abs(y_min - merged_box[\"y_min\"]) < 19:\n                # Merge the boxes and the text\n                merged_box[\"text\"] += \" \" + text\n                merged_box[\"x_min\"] = min(merged_box[\"x_min\"], x_min)\n                merged_box[\"y_min\"] = min(merged_box[\"y_min\"], y_min)\n                merged_box[\"x_max\"] = max(merged_box[\"x_max\"], x_max)\n                merged_box[\"y_max\"] = max(merged_box[\"y_max\"], y_max)\n            else:\n                # Save the merged box and start a new one\n                merged_text_boxes.append(merged_box)\n                merged_box = {\"text\": text, \"x_min\": x_min, \"y_min\": y_min, \"x_max\": x_max, \"y_max\": y_max}\n\n    # Append the last merged box\n    if merged_box:\n        merged_text_boxes.append(merged_box)\n\n    # Now process the merged text boxes\n    for box in merged_text_boxes:\n        text = box[\"text\"]\n\n        # Correct 'o' to 'oz' if followed by a number or 'o' with or without a space\n        corrected_text = text\n        # Check for non-weight units and ignore them\n        if non_weight_pattern.search(corrected_text):\n            continue  # Skip non-weight values such as \"mAh\"\n\n        # Find weight-related text only\n        weight_matches = weight_pattern.findall(corrected_text)\n        if weight_matches:\n            for match in weight_matches:\n                # Crop the image for the matched weight text\n                crop_img = image[max(box[\"y_min\"] - 10, 0):min(box[\"y_max\"] + 10, image.shape[0]),\n                                 max(box[\"x_min\"] - 10, 0):min(box[\"x_max\"] + 10, image.shape[1])]\n                preprocessed_image = preprocess_image(crop_img)\n\n                # Count black and white pixels for inversion decision\n                black_pixels = cv2.countNonZero(cv2.bitwise_not(preprocessed_image))\n                white_pixels = cv2.countNonZero(preprocessed_image)\n                if black_pixels > white_pixels:\n                    preprocessed_image = cv2.bitwise_not(preprocessed_image)\n\n                # Perform OCR on the preprocessed image\n                custom_config = r'--oem 3 --psm 6'\n                detected_text = pytesseract.image_to_string(preprocessed_image, config=custom_config).strip()\n\n                # Check if detected_text is valid and non-empty\n                if detected_text:\n                    cropped_images.append(preprocessed_image)\n                    cropped_texts.append(detected_text)\n\n    return cropped_images, cropped_texts\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:52:00.444628Z","iopub.execute_input":"2024-09-15T16:52:00.445376Z","iopub.status.idle":"2024-09-15T16:52:00.466018Z","shell.execute_reply.started":"2024-09-15T16:52:00.445331Z","shell.execute_reply":"2024-09-15T16:52:00.464456Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"markdown","source":"# Height,Width,Depth","metadata":{}},{"cell_type":"code","source":"import re\nimport cv2\nimport numpy as np\nimport pytesseract\n\ndef find_and_crop_height(image_path, keywords=None):\n    if keywords is None:\n        keywords = [\"cm\", \"mm\", \"meters\", \"feet\", \"inches\", \"ft\", \"inch\", \"m\", \"M\", 'CM', 'MM', 'IN', 'INCH', 'meter', 'ft', 'Feet']\n\n    # Load the image and detect text boxes using your `process_and_detect_text` function\n    image, prediction_groups = process_and_detect_text(image_path)\n    cropped_images = []\n    cropped_texts = []\n\n    # Pattern to match a number followed by a height unit\n    pattern = re.compile(r'(?<!\\d)(\\d+\\.?\\d*)\\s*(' + r'|'.join(keywords) + r')(?!\\w)', re.IGNORECASE)\n\n    # Merge text boxes that are close to each other\n    merged_text_boxes = []\n    merged_box = None\n    for i, (text, box) in enumerate(prediction_groups[0]):\n        box = np.int0(box)\n        x_min, y_min = np.min(box[:, 0]), np.min(box[:, 1])\n        x_max, y_max = np.max(box[:, 0]), np.max(box[:, 1])\n\n        if merged_box is None:\n            merged_box = {\"text\": text, \"x_min\": x_min, \"y_min\": y_min, \"x_max\": x_max, \"y_max\": y_max}\n        else:\n            # Check if the current box is close to the previous box (both horizontally and vertically)\n            if x_min - merged_box[\"x_max\"] < 19 and abs(y_min - merged_box[\"y_min\"]) < 19:\n                # Merge the boxes and the text\n                merged_box[\"text\"] += \" \" + text\n                merged_box[\"x_min\"] = min(merged_box[\"x_min\"], x_min)\n                merged_box[\"y_min\"] = min(merged_box[\"y_min\"], y_min)\n                merged_box[\"x_max\"] = max(merged_box[\"x_max\"], x_max)\n                merged_box[\"y_max\"] = max(merged_box[\"y_max\"], y_max)\n            else:\n                # Save the merged box and start a new one\n                merged_text_boxes.append(merged_box)\n                merged_box = {\"text\": text, \"x_min\": x_min, \"y_min\": y_min, \"x_max\": x_max, \"y_max\": y_max}\n\n    # Append the last merged box\n    if merged_box:\n        merged_text_boxes.append(merged_box)\n    for box in merged_text_boxes:\n        text = box[\"text\"]\n\n        # Correct 'o' to 'oz' if followed by a number or 'o' with or without a space\n        corrected_text = re.sub(r'(\\d+\\.?\\d*)\\s*o\\b', r'\\1 oz', text, flags=re.IGNORECASE)\n        \n        # Handle cases where 'o' might be alone or split from 'oz'\n        corrected_text = re.sub(r'(\\d+\\.?\\d*)\\s*o\\s*', r'\\1 oz ', corrected_text, flags=re.IGNORECASE)\n        \n        if pattern.search(corrected_text):\n            crop_img = image[max(box[\"y_min\"] - 10, 0):min(box[\"y_max\"] + 10, image.shape[0]),\n                             max(box[\"x_min\"] - 10, 0):min(box[\"x_max\"] + 10, image.shape[1])]\n            preprocessed_image = preprocess_image(crop_img)\n\n            # Count black and white pixels for inversion decision\n            black_pixels = cv2.countNonZero(cv2.bitwise_not(preprocessed_image))\n            white_pixels = cv2.countNonZero(preprocessed_image)\n            if black_pixels > white_pixels:\n                preprocessed_image = cv2.bitwise_not(preprocessed_image)\n\n            # Perform OCR on the preprocessed image\n            custom_config = r'--oem 3 --psm 6'\n            detected_text = pytesseract.image_to_string(preprocessed_image, config=custom_config).strip()\n\n            # Check if detected_text is valid and non-empty\n            if detected_text:\n                cropped_images.append(preprocessed_image)\n                cropped_texts.append(detected_text)\n\n    return cropped_images, cropped_texts\n    print('done')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:52:00.839568Z","iopub.execute_input":"2024-09-15T16:52:00.840404Z","iopub.status.idle":"2024-09-15T16:52:00.858382Z","shell.execute_reply.started":"2024-09-15T16:52:00.840341Z","shell.execute_reply":"2024-09-15T16:52:00.857234Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"markdown","source":"# Voltage","metadata":{}},{"cell_type":"code","source":"import re\nimport cv2\nimport numpy as np\nimport pytesseract\n\ndef find_and_crop_voltage(image_path, keywords=None):\n    if keywords is None:\n        keywords = [\"V\", \"volts\", \"Volts\", \"v\", \"Volt\"]\n\n    image, prediction_groups = process_and_detect_text(image_path)\n    cropped_images = []\n    cropped_texts = []\n\n    # Pattern to match a number followed by a voltage unit\n    pattern = re.compile(r'(?<!\\d)(\\d+\\.?\\d*)\\s*(' + r'|'.join(keywords) + r')\\b', re.IGNORECASE)\n    merged_text_boxes = []\n    merged_box = None\n    for i, (text, box) in enumerate(prediction_groups[0]):\n        box = np.int0(box)\n        x_min, y_min = np.min(box[:, 0]), np.min(box[:, 1])\n        x_max, y_max = np.max(box[:, 0]), np.max(box[:, 1])\n\n        if merged_box is None:\n            merged_box = {\"text\": text, \"x_min\": x_min, \"y_min\": y_min, \"x_max\": x_max, \"y_max\": y_max}\n        else:\n            # Check if the current box is close to the previous box (both horizontally and vertically)\n            if x_min - merged_box[\"x_max\"] < 19 and abs(y_min - merged_box[\"y_min\"]) < 19:\n                # Merge the boxes and the text\n                merged_box[\"text\"] += \" \" + text\n                merged_box[\"x_min\"] = min(merged_box[\"x_min\"], x_min)\n                merged_box[\"y_min\"] = min(merged_box[\"y_min\"], y_min)\n                merged_box[\"x_max\"] = max(merged_box[\"x_max\"], x_max)\n                merged_box[\"y_max\"] = max(merged_box[\"y_max\"], y_max)\n            else:\n                # Save the merged box and start a new one\n                merged_text_boxes.append(merged_box)\n                merged_box = {\"text\": text, \"x_min\": x_min, \"y_min\": y_min, \"x_max\": x_max, \"y_max\": y_max}\n\n    # Append the last merged box\n    if merged_box:\n        merged_text_boxes.append(merged_box)\n    for box in merged_text_boxes:\n        text = box[\"text\"]\n\n        # Correct 'o' to 'oz' if followed by a number or 'o' with or without a space\n        corrected_text = re.sub(r'(\\d+\\.?\\d*)\\s*o\\b', r'\\1 oz', text, flags=re.IGNORECASE)\n        \n        # Handle cases where 'o' might be alone or split from 'oz'\n        corrected_text = re.sub(r'(\\d+\\.?\\d*)\\s*o\\s*', r'\\1 oz ', corrected_text, flags=re.IGNORECASE)\n        \n        if pattern.search(corrected_text):\n            crop_img = image[max(box[\"y_min\"] - 10, 0):min(box[\"y_max\"] + 10, image.shape[0]),\n                             max(box[\"x_min\"] - 10, 0):min(box[\"x_max\"] + 10, image.shape[1])]\n            preprocessed_image = preprocess_image(crop_img)\n\n            # Count black and white pixels for inversion decision\n            black_pixels = cv2.countNonZero(cv2.bitwise_not(preprocessed_image))\n            white_pixels = cv2.countNonZero(preprocessed_image)\n            if black_pixels > white_pixels:\n                preprocessed_image = cv2.bitwise_not(preprocessed_image)\n\n            # Perform OCR on the preprocessed image\n            custom_config = r'--oem 3 --psm 6'\n            detected_text = pytesseract.image_to_string(preprocessed_image, config=custom_config).strip()\n\n            # Check if detected_text is valid and non-empty\n            if detected_text:\n                cropped_images.append(preprocessed_image)\n                cropped_texts.append(detected_text)\n\n    return cropped_images, cropped_texts\n    print('done')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:52:01.199405Z","iopub.execute_input":"2024-09-15T16:52:01.200271Z","iopub.status.idle":"2024-09-15T16:52:01.217912Z","shell.execute_reply.started":"2024-09-15T16:52:01.200227Z","shell.execute_reply":"2024-09-15T16:52:01.216701Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"markdown","source":"# Wattage","metadata":{}},{"cell_type":"code","source":"import re\nimport cv2\nimport numpy as np\nimport pytesseract\n\ndef find_and_crop_wattage(image_path, keywords=None):\n    if keywords is None:\n        keywords = [\n    \"W\", \"w\", \"kW\", \"MW\", \"GW\", \"Wh\", \"kWh\", \"MWh\", \"GWh\", \n    \"VA\", \"kVA\", \"MVA\", \"ow\", \"oW\"  # Extend as needed\n]\n\n    # Ensure the image is preprocessed and OCR pipeline is applied\n    image, prediction_groups = process_and_detect_text(image_path)\n    cropped_images = []\n    cropped_texts = []\n\n    # Pattern to match a number followed by a wattage unit\n    pattern = re.compile(r'(?<!\\d)(\\d+\\.?\\d*)\\s*(' + r'|'.join(keywords) + r')\\b', re.IGNORECASE)\n\n    merged_text_boxes = []\n    merged_box = None\n    for i, (text, box) in enumerate(prediction_groups[0]):\n        box = np.int0(box)\n        x_min, y_min = np.min(box[:, 0]), np.min(box[:, 1])\n        x_max, y_max = np.max(box[:, 0]), np.max(box[:, 1])\n\n        if merged_box is None:\n            merged_box = {\"text\": text, \"x_min\": x_min, \"y_min\": y_min, \"x_max\": x_max, \"y_max\": y_max}\n        else:\n            # Check if the current box is close to the previous box (both horizontally and vertically)\n            if x_min - merged_box[\"x_max\"] < 19 and abs(y_min - merged_box[\"y_min\"]) < 19:\n                # Merge the boxes and the text\n                merged_box[\"text\"] += \" \" + text\n                merged_box[\"x_min\"] = min(merged_box[\"x_min\"], x_min)\n                merged_box[\"y_min\"] = min(merged_box[\"y_min\"], y_min)\n                merged_box[\"x_max\"] = max(merged_box[\"x_max\"], x_max)\n                merged_box[\"y_max\"] = max(merged_box[\"y_max\"], y_max)\n            else:\n                # Save the merged box and start a new one\n                merged_text_boxes.append(merged_box)\n                merged_box = {\"text\": text, \"x_min\": x_min, \"y_min\": y_min, \"x_max\": x_max, \"y_max\": y_max}\n\n    # Append the last merged box\n    if merged_box:\n        merged_text_boxes.append(merged_box)\n\n    for box in merged_text_boxes:\n        text = box[\"text\"]\n\n        if pattern.search(text):\n            crop_img = image[max(box[\"y_min\"] - 10, 0):min(box[\"y_max\"] + 10, image.shape[0]),\n                             max(box[\"x_min\"] - 10, 0):min(box[\"x_max\"] + 10, image.shape[1])]\n            preprocessed_image = preprocess_image(crop_img)\n            # Count black and white pixels for inversion decision\n            black_pixels = cv2.countNonZero(cv2.bitwise_not(preprocessed_image))\n            white_pixels = cv2.countNonZero(preprocessed_image)\n            if black_pixels > white_pixels:\n                preprocessed_image = cv2.bitwise_not(preprocessed_image)\n\n            # Perform OCR on the preprocessed image\n            custom_config = r'--oem 3 --psm 6'\n            detected_text = pytesseract.image_to_string(preprocessed_image, config=custom_config).strip()\n\n            # Check if detected_text is valid and non-empty\n            if detected_text:\n                cropped_images.append(preprocessed_image)\n                cropped_texts.append(detected_text)\n\n    return cropped_images, cropped_texts\n\n    print('done')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:52:01.549566Z","iopub.execute_input":"2024-09-15T16:52:01.550472Z","iopub.status.idle":"2024-09-15T16:52:01.566530Z","shell.execute_reply.started":"2024-09-15T16:52:01.550424Z","shell.execute_reply":"2024-09-15T16:52:01.565345Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"markdown","source":"# Main Function","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\n\n# Define a mapping of unit abbreviations to their full forms\nunit_mapping = {\n    'kg': 'kilogram', 'gm': 'gram', 'g': 'gram', 'mg': 'milligram',\n    'grams': 'gram', 'milligrams': 'milligram', 'kilograms': 'kilogram',\n    'G': 'gram', 'KG': 'kilogram', 'Kg': 'kilogram', 'lb': 'pound','lbs': 'pound',\n    'cm': 'centimeter', 'm': 'meter', 'millimeters': 'millimeter',\n    'mm': 'millimeter', 'meters': 'meter', 'CM': 'centimeter', 'M': 'meter', 'MM': 'millimeter',\n    'V': 'volt', 'volts': 'volt', 'Volt': 'volt', 'v': 'volt',\n    'W': 'watt', 'watts': 'watt', 'Watts': 'watt', 'w': 'watt', 'Watt': 'watt',\n    'KGS':'kilogram'\n}\n\ndef call_heuristic(entity, text):\n    corrected_text = []\n    if entity in ['item_weight', 'maximum_weight_recommendation']:\n        corrected_text = heuristic_correction_weight(text)\n\n    elif entity in ['height', 'depth', 'width']:\n        corrected_text = heuristic_correction_height(text)\n\n    elif entity in ['voltage']:\n        corrected_text = heuristic_correction_voltage(text)\n\n    elif entity in ['wattage']:\n        corrected_text = heuristic_correction_watts(text)\n        \n    return corrected_text    \n\ndef extract_numbers_and_units(cropped_texts, keywords, entity):\n    # Regex pattern to extract numbers and units with optional spaces between\n    pattern = re.compile(r'(\\d+\\.?\\d*)\\s*(' + '|'.join(keywords) + r')\\b', re.IGNORECASE)\n    extracted_info = []\n    \n    for text in cropped_texts:\n        # Apply the heuristic correction based on entity type\n        corrected_text = call_heuristic(entity, text)\n        \n        matches = pattern.findall(corrected_text)  # Find all matches\n        \n        for match in matches:\n            number, unit = match\n            full_unit = unit_mapping.get(unit.lower(), unit)  # Get the full form of the unit\n            extracted_info.append(f\"{number} {full_unit}\")\n        \n        # If the entity is 'voltage' or 'wattage', call extract_value_and_unit\n        if entity in ['voltage', 'wattage']:\n            extracted_info = [extract_value_and_unit(info, entity) for info in extracted_info]\n    \n    print(extracted_info)\n    return extracted_info\n\n# Main function to process each row\ndef process_row(row):\n    image_path = row['image_link']\n    entity = row['entity_name'].lower()\n    extracted_info = []\n\n    cropped_images, cropped_texts = [], []\n\n    if entity in ['item_weight', 'maximum_weight_recommendation']:\n        cropped_images, cropped_texts = find_and_crop_weight(image_path)\n        extracted_info = extract_numbers_and_units(cropped_texts, [\"kg\", \"gm\", \"g\", \"mg\", \"grams\", \"milligrams\", \"kilograms\", 'G', 'KG', 'Kg', 'pounds', 'oz','lb','lbs','KGS'], entity)\n\n    elif entity in ['height', 'depth', 'width']:\n        cropped_images, cropped_texts = find_and_crop_height(image_path)\n        extracted_info = extract_numbers_and_units(cropped_texts, [\"cm\", \"m\", \"millimeters\", \"mm\", \"meters\", \"CM\", \"M\", \"MM\"], entity)\n\n    elif entity in ['voltage']:\n        cropped_images, cropped_texts = find_and_crop_voltage(image_path)\n        extracted_info = extract_numbers_and_units(cropped_texts, [\"V\", \"volts\", \"Volts\", \"v\", \"Volt\"], entity)\n\n    elif entity in ['wattage']:\n        cropped_images, cropped_texts = find_and_crop_wattage(image_path)\n        extracted_info = extract_numbers_and_units(cropped_texts, [\"W\", \"w\", \"kW\", \"MW\", \"GW\", \"Wh\", \"kWh\", \"MWh\", \"GWh\", \"VA\", \"kVA\", \"MVA\"], entity)\n\n    # Print the text extracted from cropped images\n    print(f\"Extracted information for {image_path}:\")\n\n    for i, info in enumerate(extracted_info):\n        print(f\"  Extracted Info {i+1}: {info}\")\n\n    # Join all extracted info into a single string separated by commas\n    return ', '.join(extracted_info)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:06:43.684988Z","iopub.execute_input":"2024-09-15T18:06:43.685953Z","iopub.status.idle":"2024-09-15T18:06:43.704717Z","shell.execute_reply.started":"2024-09-15T18:06:43.685906Z","shell.execute_reply":"2024-09-15T18:06:43.703773Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef heuristic_correction_weight(predicted_str):\n    # Define a list of valid units including 'oz'\n    valid_units = ['mg', 'g', 'kg', 'A', 'mA', 'KG', 'oz','lb','lbs']  # Extend this list as needed\n\n    # Step 1: Remove any non-alphabetic and non-numeric characters at the end, except valid units or numbers\n    trimmed_text = re.sub(r'[^\\w\\s]+$', '', predicted_str)\n\n    # Step 2: If special symbols like ¢ are detected, replace them with 'g' (assuming ¢ is mistaken for 'g')\n    corrected_text = re.sub(r'[¢]', 'g', trimmed_text)\n\n    # Step 3: Extract numeric part and unit part using regex\n    matches = re.findall(r'([0-9\\.]+)\\s*([a-zA-Z]*)', corrected_text)\n\n    corrected_str = \"\"\n    for value, unit in matches:\n        corrected_value = value\n\n        # Step 4: Check if the number ends with '9', '8', or '6'\n        if re.search(r'[9]$', corrected_value):\n            # Remove the trailing '9', '8', or '6' and append 'g'\n            corrected_value = re.sub(r'[986]$', '', corrected_value)  # Remove last digit\n            corrected_unit = 'g'  # Automatically append 'g'\n        else:\n            # If unit is close to a valid unit, replace it with the closest match\n            corrected_unit = closest_unit(unit, valid_units) if unit else 'g'  # Assume 'g' if no unit is present\n        \n        # Special case for 'o' being mistaken for 'oz'\n        if corrected_unit == '' and re.search(r'(\\d+\\.?\\d*)\\s*o\\b', predicted_str):\n            corrected_unit = 'oz'\n        \n        corrected_str += f\"{corrected_value}{corrected_unit}, \"\n\n    return corrected_str.strip(', ')\n\n# Function to find the closest unit using Levenshtein distance\ndef closest_unit(predicted_unit, valid_units):\n    closest = min(valid_units, key=lambda x: levenshtein_distance(predicted_unit, x))\n    return closest\n\n# Levenshtein distance for measuring similarity between units\ndef levenshtein_distance(a, b):\n    m, n = len(a), len(b)\n    dp = [[0] * (n+1) for _ in range(m+1)]\n\n    for i in range(m+1):\n        for j in range(n+1):\n            if i == 0:\n                dp[i][j] = j\n            elif j == 0:\n                dp[i][j] = i\n            elif a[i-1] == b[j-1]:\n                dp[i][j] = dp[i-1][j-1]\n            else:\n                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])\n\n    return dp[m][n]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:52:02.719435Z","iopub.execute_input":"2024-09-15T16:52:02.719853Z","iopub.status.idle":"2024-09-15T16:52:02.734494Z","shell.execute_reply.started":"2024-09-15T16:52:02.719815Z","shell.execute_reply":"2024-09-15T16:52:02.733419Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"code","source":"import re\nimport numpy as np\n\n# Define valid height units\nvalid_units = ['cm', 'mm', 'meters', 'feet', 'ft', 'inch', 'm', 'in','MM']  # Extend as needed\n\ndef closest_unit(unit, valid_units):\n    \"\"\"Find the closest valid unit to the given unit using Levenshtein distance.\"\"\"\n    if not unit:\n        return 'cm'  # Default to 'cm' if no unit provided\n\n    closest = min(valid_units, key=lambda x: levenshtein_distance(unit, x))\n    return closest\n\ndef levenshtein_distance(a, b):\n    \"\"\"Calculate Levenshtein distance between two strings.\"\"\"\n    m, n = len(a), len(b)\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\n\n    for i in range(m + 1):\n        for j in range(n + 1):\n            if i == 0:\n                dp[i][j] = j\n            elif j == 0:\n                dp[i][j] = i\n            elif a[i - 1] == b[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[m][n]\n\ndef heuristic_correction_height(predicted_str):\n    # Remove non-alphabetic and non-numeric characters at the end\n    trimmed_text = re.sub(r'[^\\w\\s\\-]+$', '', predicted_str)\n\n    # Special symbols correction\n    corrected_text = re.sub(r'[¢]', 'cm', trimmed_text)  # Assuming ¢ could be a mistake for cm\n\n    # Extract ranges and individual values\n    matches = re.findall(r'([0-9\\.]+)\\s*[-]?\\s*([0-9\\.]*)\\s*([a-zA-Z]*)', corrected_text)\n\n    corrected_str = \"\"\n    for value1, value2, unit in matches:\n        if value2:  # If there's a second value, it's a range\n            corrected_value1 = value1\n            corrected_value2 = value2\n            corrected_unit = closest_unit(unit, valid_units) if unit else 'cm'  # Default to 'cm'\n            corrected_str += f\"{corrected_value1} {corrected_unit} - {corrected_value2} {corrected_unit}, \"\n        else:  # Single value\n            corrected_value = value1\n            corrected_unit = closest_unit(unit, valid_units) if unit else 'cm'  # Default to 'cm'\n            corrected_str += f\"{corrected_value} {corrected_unit}, \"\n\n    return corrected_str.strip(', ')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:52:56.324989Z","iopub.execute_input":"2024-09-15T16:52:56.326098Z","iopub.status.idle":"2024-09-15T16:52:56.340244Z","shell.execute_reply.started":"2024-09-15T16:52:56.326046Z","shell.execute_reply":"2024-09-15T16:52:56.339050Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"code","source":"import re\nimport numpy as np\n\n# Define valid voltage units\nvalid_units = [\n    \"Volt\", \"Volts\", \"V\", \"v\", \"mV\", \"kV\", \"MV\", \"µV\", \n    \"VDC\", \"VAC\", \"DCV\", \"ACV\"  # Extend as needed\n]\n\ndef closest_unit(unit, valid_units):\n    \"\"\"Find the closest valid unit to the given unit using Levenshtein distance.\"\"\"\n    if not unit:\n        return 'v'  # Default to 'v' if no unit provided\n\n    # If the unit is 'w', return an empty string (no conversion)\n    if unit.lower() == 'w':\n        return ''\n\n    # Otherwise, find the closest valid unit using Levenshtein distance\n    closest = min(valid_units, key=lambda x: levenshtein_distance(unit, x))\n    return closest\n\ndef levenshtein_distance(a, b):\n    \"\"\"Calculate Levenshtein distance between two strings.\"\"\"\n    m, n = len(a), len(b)\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\n\n    for i in range(m + 1):\n        for j in range(n + 1):\n            if i == 0:\n                dp[i][j] = j\n            elif j == 0:\n                dp[i][j] = i\n            elif a[i - 1] == b[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[m][n]\n\ndef heuristic_correction_voltage(predicted_str):\n    # Remove non-alphabetic and non-numeric characters at the end\n    trimmed_text = re.sub(r'[^\\w\\s\\-]+$', '', predicted_str)\n\n    # Special symbols correction\n    corrected_text = re.sub(r'[¢]', 'v', trimmed_text)  # Assuming ¢ could be a mistake for v\n    \n    # Extract ranges and individual values\n    matches = re.findall(r'([0-9\\.]+)\\s*[-]?\\s*([0-9\\.]*)\\s*([a-zA-Z]*)', corrected_text)\n\n    corrected_str = \"\"\n    for value1, value2, unit in matches:\n        if value2:  # If there's a second value, it's a range\n            corrected_value1 = value1\n            corrected_value2 = value2\n            corrected_unit = closest_unit(unit, valid_units) if unit else 'v'  # Default to 'v'\n            if corrected_unit:  # Only append if the unit isn't empty (for 'w')\n                corrected_str += f\"{corrected_value1} {corrected_unit} - {corrected_value2} {corrected_unit}, \"\n            else:  # If the unit is 'w', only add the values without the unit\n                corrected_str += f\"{corrected_value1} - {corrected_value2}, \"\n        else:  # Single value\n            corrected_value = value1\n            corrected_unit = closest_unit(unit, valid_units) if unit else 'v'  # Default to 'v'\n            if corrected_unit:  # Only append if the unit isn't empty (for 'w')\n                corrected_str += f\"{corrected_value} {corrected_unit}, \"\n            else:  # If the unit is 'w', only add the value without the unit\n                corrected_str += f\"{corrected_value}, \"\n\n    return corrected_str.strip(', ')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:52:03.634717Z","iopub.execute_input":"2024-09-15T16:52:03.635161Z","iopub.status.idle":"2024-09-15T16:52:03.651674Z","shell.execute_reply.started":"2024-09-15T16:52:03.635117Z","shell.execute_reply":"2024-09-15T16:52:03.650627Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"import re\nimport numpy as np\n\n# Define valid power units\nvalid_power_units = [\n    \"W\", \"w\", \"kW\", \"MW\", \"GW\", \"Wh\", \"kWh\", \"MWh\", \"GWh\", \n    \"VA\", \"kVA\", \"MVA\"  # Extend as needed\n]\n\ndef closest_power_unit(unit, valid_power_units):\n    \"\"\"Find the closest valid power unit to the given unit using Levenshtein distance.\"\"\"\n    if not unit:\n        return 'W'  # Default to 'W' if no unit provided\n\n    # Otherwise, find the closest valid unit using Levenshtein distance\n    closest = min(valid_power_units, key=lambda x: levenshtein_distance(unit, x))\n    return closest\n\ndef levenshtein_distance(a, b):\n    \"\"\"Calculate Levenshtein distance between two strings.\"\"\"\n    m, n = len(a), len(b)\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\n\n    for i in range(m + 1):\n        for j in range(n + 1):\n            if i == 0:\n                dp[i][j] = j\n            elif j == 0:\n                dp[i][j] = i\n            elif a[i - 1] == b[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n\n    return dp[m][n]\n\ndef heuristic_correction_watts(predicted_str):\n    # Remove non-alphabetic and non-numeric characters at the end\n    trimmed_text = re.sub(r'[^\\w\\s\\-]+$', '', predicted_str)\n\n    # Special symbols correction\n    corrected_text = re.sub(r'[¢]', 'W', trimmed_text)  # Assuming ¢ could be a mistake for W\n    \n    # Extract ranges and individual values\n    matches = re.findall(r'([0-9\\.]+)\\s*[-]?\\s*([0-9\\.]*)\\s*([a-zA-Z]*)', corrected_text)\n\n    corrected_str = \"\"\n    for value1, value2, unit in matches:\n        if value2:  # If there's a second value, it's a range\n            corrected_value1 = value1\n            corrected_value2 = value2\n            corrected_unit = closest_power_unit(unit, valid_power_units) if unit else 'W'  # Default to 'W'\n            corrected_str += f\"{corrected_value1} {corrected_unit} - {corrected_value2} {corrected_unit}, \"\n        else:  # Single value\n            corrected_value = value1\n            corrected_unit = closest_power_unit(unit, valid_power_units) if unit else 'W'  # Default to 'W'\n            corrected_str += f\"{corrected_value} {corrected_unit}, \"\n\n    return corrected_str.strip(', ')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:52:04.064678Z","iopub.execute_input":"2024-09-15T16:52:04.065068Z","iopub.status.idle":"2024-09-15T16:52:04.079037Z","shell.execute_reply.started":"2024-09-15T16:52:04.065032Z","shell.execute_reply":"2024-09-15T16:52:04.077909Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"import re\n\n# Function to map the extracted unit to the desired form based on entity_type\ndef map_unit(value, unit, entity_type):\n    if entity_type == 'voltage' and unit == 'V':  # Voltage transformation\n        if value < 1:\n            return f\"{value * 1000} millivolt\"\n        elif value >= 1000:\n            return f\"{value / 1000} kilovolt\"\n        else:\n            return f\"{value} volt\"\n    elif entity_type == 'wattage' and unit == 'W':  # Wattage transformation\n        if value >= 1000:\n            return f\"{value / 1000} kilowatt\"\n        else:\n            return f\"{value} watt\"\n    # Default mapping if the entity_type does not match\n    return f\"{value} {unit}\"\n\n# Function to extract and map the numeric value and unit\ndef extract_value_and_unit(text, entity_type):\n    # Regular expression to capture numeric value and unit (including values without space like '54W')\n    matches = re.findall(r'(\\d+\\.?\\d*)\\s*([VWvw]|[Vv]olt[s]?|[Ww]att[s]?)', text)\n\n    if matches:\n        # Filter matches based on the entity_type priority\n        for value, unit in matches:\n            # Handle different variations of voltage units\n            if entity_type == 'voltage' and unit.lower() in ['v', 'volt', 'volts']:\n                return map_unit(float(value), 'V', entity_type)  # Use standardized 'V' for voltage\n\n            # Handle different variations of wattage units\n            elif entity_type == 'wattage' and unit.lower() in ['w', 'watt', 'watts']:\n                return map_unit(float(value), 'W', entity_type)  # Use standardized 'W' for wattage\n\n        # If no match is found based on entity_type, return the first match found\n        value, unit = matches[0]\n        if unit.lower() in ['v', 'volt', 'volts']:\n            return map_unit(float(value), 'V', entity_type)\n        elif unit.lower() in ['w', 'watt', 'watts']:\n            return map_unit(float(value), 'W', entity_type)\n\n    else:\n        return \"No valid value and unit found\"\n\n\n# Example usage\ndata = {'entity_type': 'wattage'}\ntext1 = \"The device operates at 1.1V / 5W\"\ntext2 = \"The voltage is 500 V\"\ntext3 = \"Power consumption is 1500W\"\n\nprint(extract_value_and_unit(text1, data['entity_type']))  # Output: \"5.0 watt\"\nprint(extract_value_and_unit(text2, 'voltage'))  # Output: \"500 volt\"\nprint(extract_value_and_unit(text3, 'wattage'))  # Output: \"1.5 kilowatt\"","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:52:04.514215Z","iopub.execute_input":"2024-09-15T16:52:04.514652Z","iopub.status.idle":"2024-09-15T16:52:04.528627Z","shell.execute_reply.started":"2024-09-15T16:52:04.514609Z","shell.execute_reply":"2024-09-15T16:52:04.527458Z"},"trusted":true},"execution_count":232,"outputs":[{"name":"stdout","text":"5.0 watt\n500.0 volt\n1.5 kilowatt\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test examples:\nexamples = [\n    \"1400MG\", \"1400nc\", \"20060\", \"A2009\", \"1009w\", \"5mw\", \"35INw\",'65w/20v', \"169q\", \"0.592kg\", \"2k\",'2009w;%^','abcd fghh sqwfg 900g dqwfe4 25g dfeve 5kg','Weight: 26¢','3o2','5cg','40cm | 30cm'\n]\n\nfor example in examples:\n    corrected = call_heuristic('width',example)\n    print(f\"Predicted: {example} -> Corrected: {corrected}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:45:52.802612Z","iopub.execute_input":"2024-09-15T18:45:52.803037Z","iopub.status.idle":"2024-09-15T18:45:52.812093Z","shell.execute_reply.started":"2024-09-15T18:45:52.802999Z","shell.execute_reply":"2024-09-15T18:45:52.810830Z"},"trusted":true},"execution_count":287,"outputs":[{"name":"stdout","text":"Predicted: 1400MG -> Corrected: 1400 cm\nPredicted: 1400nc -> Corrected: 1400 cm\nPredicted: 20060 -> Corrected: 20060 cm\nPredicted: A2009 -> Corrected: 2009 cm\nPredicted: 1009w -> Corrected: 1009 m\nPredicted: 5mw -> Corrected: 5 mm\nPredicted: 35INw -> Corrected: 35 cm\nPredicted: 65w/20v -> Corrected: 65 m, 20 m\nPredicted: 169q -> Corrected: 169 m\nPredicted: 0.592kg -> Corrected: 0.592 cm\nPredicted: 2k -> Corrected: 2 m\nPredicted: 2009w;%^ -> Corrected: 2009 m\nPredicted: abcd fghh sqwfg 900g dqwfe4 25g dfeve 5kg -> Corrected: 900 m, 4 m - 25 m, 5 cm\nPredicted: Weight: 26¢ -> Corrected: 26 cm\nPredicted: 3o2 -> Corrected: 3 m, 2 cm\nPredicted: 5cg -> Corrected: 5 cm\nPredicted: 40cm | 30cm -> Corrected: 40 cm, 30 cm\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the dataset (assuming the dataset is in CSV format)\ndf = pd.read_csv('/kaggle/input/testing2/test.csv')\n\n# Taking a random sample of 100 rows for testing\n\n# Applying the process_row function to each row and assigning the result to a new column\ndf['detected_text2'] = df.apply(lambda row: process_row(row), axis=1)\n\n# Display the first few rows to check results\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:46:09.887738Z","iopub.execute_input":"2024-09-15T18:46:09.888151Z","iopub.status.idle":"2024-09-15T18:46:50.167808Z","shell.execute_reply.started":"2024-09-15T18:46:09.888117Z","shell.execute_reply":"2024-09-15T18:46:50.166496Z"},"trusted":true},"execution_count":288,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 83ms/step\n1/1 [==============================] - 0s 40ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/110EibNyclL.jpg:\n1/1 [==============================] - 0s 24ms/step\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 42ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/11TU2clswzL.jpg:\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 44ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/11TU2clswzL.jpg:\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 47ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/11TU2clswzL.jpg:\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 45ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/11gHj8dhhrL.jpg:\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 45ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/11gHj8dhhrL.jpg:\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 54ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/11gHj8dhhrL.jpg:\n1/1 [==============================] - 0s 78ms/step\n1/1 [==============================] - 0s 36ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/11lshEUmCrL.jpg:\n1/1 [==============================] - 0s 78ms/step\n1/1 [==============================] - 0s 39ms/step\n['40 centimeter', '30 centimeter', '1 meter']\nExtracted information for https://m.media-amazon.com/images/I/21+i52HRW4L.jpg:\n  Extracted Info 1: 40 centimeter\n  Extracted Info 2: 30 centimeter\n  Extracted Info 3: 1 meter\n1/1 [==============================] - 0s 77ms/step\n1/1 [==============================] - 0s 38ms/step\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"['40 centimeter', '30 centimeter', '185 centimeter']\nExtracted information for https://m.media-amazon.com/images/I/21-LmSmehZL.jpg:\n  Extracted Info 1: 40 centimeter\n  Extracted Info 2: 30 centimeter\n  Extracted Info 3: 185 centimeter\n1/1 [==============================] - 0s 80ms/step\n1/1 [==============================] - 0s 41ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/213oP6n7jtL.jpg:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3507051408.py:28: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 33ms/step\n1/1 [==============================] - 0s 36ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/213wY3gUsmL.jpg:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 77ms/step\n1/1 [==============================] - 0s 36ms/step\n['4 centimeter', '310 centimeter', '10 centimeter']\nExtracted information for https://m.media-amazon.com/images/I/214CLs1oznL.jpg:\n  Extracted Info 1: 4 centimeter\n  Extracted Info 2: 310 centimeter\n  Extracted Info 3: 10 centimeter\n1/1 [==============================] - 0s 82ms/step\n1/1 [==============================] - 0s 36ms/step\n['4 centimeter', '310 centimeter', '10 centimeter']\nExtracted information for https://m.media-amazon.com/images/I/214CLs1oznL.jpg:\n  Extracted Info 1: 4 centimeter\n  Extracted Info 2: 310 centimeter\n  Extracted Info 3: 10 centimeter\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 77ms/step\n1/1 [==============================] - 0s 36ms/step\n['4 centimeter', '310 centimeter', '10 centimeter']\nExtracted information for https://m.media-amazon.com/images/I/214CLs1oznL.jpg:\n  Extracted Info 1: 4 centimeter\n  Extracted Info 2: 310 centimeter\n  Extracted Info 3: 10 centimeter\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 77ms/step\n1/1 [==============================] - 0s 45ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/216rjgJHAeL.jpg:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3507051408.py:28: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 34ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/2174yonQBtL.jpg:\n1/1 [==============================] - 0s 30ms/step\n1/1 [==============================] - 0s 48ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/218BCzgKxuL.jpg:\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 47ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/218BCzgKxuL.jpg:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/762548290.py:24: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 33ms/step\n1/1 [==============================] - 0s 48ms/step\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/339695463.py:19: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"['208.0 volt', '240.0 volt']\nExtracted information for https://m.media-amazon.com/images/I/218BCzgKxuL.jpg:\n  Extracted Info 1: 208.0 volt\n  Extracted Info 2: 240.0 volt\n1/1 [==============================] - 0s 59ms/step\n1/1 [==============================] - 0s 33ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21BMc5GC4iL.jpg:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 40ms/step\n1/1 [==============================] - 0s 33ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21CxlWbim3L.jpg:\nExtracted information for https://m.media-amazon.com/images/I/21DZ7BAZ6-L.jpg:\n1/1 [==============================] - 0s 78ms/step\n1/1 [==============================] - 0s 36ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21GLFXwC1mS.jpg:\n1/1 [==============================] - 0s 85ms/step\n1/1 [==============================] - 0s 34ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21GLFXwC1mS.jpg:\n1/1 [==============================] - 0s 64ms/step\n1/1 [==============================] - 0s 35ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21H+7R85YZL.jpg:\n1/1 [==============================] - 0s 66ms/step\n1/1 [==============================] - 0s 36ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21H+7R85YZL.jpg:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 65ms/step\n1/1 [==============================] - 0s 38ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21IGmiJi-PL.jpg:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3507051408.py:28: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 81ms/step\n1/1 [==============================] - 0s 37ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21Is45vdL0L.jpg:\n1/1 [==============================] - 0s 34ms/step\n1/1 [==============================] - 0s 45ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21Raw7jSIML.jpg:\n1/1 [==============================] - 0s 79ms/step\n1/1 [==============================] - 0s 45ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21Vc5ixqKpS.jpg:\n1/1 [==============================] - 0s 76ms/step\n1/1 [==============================] - 0s 36ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21W7FvftSCL.jpg:\n1/1 [==============================] - 0s 66ms/step\n1/1 [==============================] - 0s 34ms/step\n['14 centimeter']\nExtracted information for https://m.media-amazon.com/images/I/21aD6ktvwxS.jpg:\n  Extracted Info 1: 14 centimeter\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 48ms/step\n1/1 [==============================] - 0s 35ms/step\n['14 centimeter']\nExtracted information for https://m.media-amazon.com/images/I/21aD6ktvwxS.jpg:\n  Extracted Info 1: 14 centimeter\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 65ms/step\n1/1 [==============================] - 0s 33ms/step\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"['14 centimeter']\nExtracted information for https://m.media-amazon.com/images/I/21aD6ktvwxS.jpg:\n  Extracted Info 1: 14 centimeter\n1/1 [==============================] - 0s 78ms/step\n1/1 [==============================] - 0s 37ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21bfrFeArAL.jpg:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3507051408.py:28: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 31ms/step\n1/1 [==============================] - 0s 39ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21bwWoCpGJL.jpg:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 46ms/step\n[]\nExtracted information for https://m.media-amazon.com/images/I/21cLufe8Y5L.jpg:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/339695463.py:19: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 43ms/step\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/762548290.py:24: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"[]\nExtracted information for https://m.media-amazon.com/images/I/21cLufe8Y5L.jpg:\n1/1 [==============================] - 0s 79ms/step\n1/1 [==============================] - 0s 45ms/step\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4017202907.py:22: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n  box = np.int0(box)\n","output_type":"stream"},{"name":"stdout","text":"['26 centimeter']\nExtracted information for https://m.media-amazon.com/images/I/21d6Dtc94mL.jpg:\n  Extracted Info 1: 26 centimeter\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3066048154.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_subset['detected_text2'] = df_subset.apply(lambda row: process_row(row), axis=1)\n","output_type":"stream"},{"execution_count":288,"output_type":"execute_result","data":{"text/plain":"   index                                         image_link  group_id  \\\n0      0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n1      1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n2      2  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n3      3  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n4      4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n\n  entity_name detected_text2  \n0      height                 \n1       width                 \n2      height                 \n3       depth                 \n4       depth                 ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>image_link</th>\n      <th>group_id</th>\n      <th>entity_name</th>\n      <th>detected_text2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>https://m.media-amazon.com/images/I/110EibNycl...</td>\n      <td>156839</td>\n      <td>height</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n      <td>792578</td>\n      <td>width</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n      <td>792578</td>\n      <td>height</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n      <td>792578</td>\n      <td>depth</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>https://m.media-amazon.com/images/I/11gHj8dhhr...</td>\n      <td>792578</td>\n      <td>depth</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:08:45.321956Z","iopub.execute_input":"2024-09-15T17:08:45.322829Z","iopub.status.idle":"2024-09-15T17:08:45.330129Z","shell.execute_reply.started":"2024-09-15T17:08:45.322784Z","shell.execute_reply":"2024-09-15T17:08:45.329154Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"code","source":" df.to_csv('/kaggle/working/processed.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:46:59.852889Z","iopub.execute_input":"2024-09-15T18:46:59.853323Z","iopub.status.idle":"2024-09-15T18:46:59.860192Z","shell.execute_reply.started":"2024-09-15T18:46:59.853284Z","shell.execute_reply":"2024-09-15T18:46:59.859063Z"},"trusted":true},"execution_count":289,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Function to process detected_text2 based on entity_name\ndef process_detected_text(entity_name, detected_text2):\n    if pd.isnull(detected_text2):\n        return np.nan  # Keep NaN for now to handle later\n    \n    values = detected_text2.split(',')  # Assuming values are comma-separated\n    if entity_name == 'height':\n        return values[0] if len(values) > 0 else np.nan\n    elif entity_name == 'width':\n        return values[1] if len(values) > 1 else np.nan\n    elif entity_name == 'depth':\n        return values[2] if len(values) > 2 else np.nan\n    else:\n        return values[0] if len(values) > 0 else np.nan\n\n# Apply the processing function to each row\ndf['processed_text'] = df.apply(lambda row: process_detected_text(row['entity_name'], row['detected_text2']), axis=1)\n\n# Compute mode for each entity_name\nmodes = df.groupby('entity_name')['processed_text'].apply(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n\n# Function to fill null values with mode\ndef fill_null_with_mode(row):\n    if pd.isnull(row['processed_text']):\n        return modes[row['entity_name']] if row['entity_name'] in modes else np.nan\n    return row['processed_text']\n\n# Apply the fill_null_with_mode function\ndf['processed_text'] = df.apply(fill_null_with_mode, axis=1)\n\n# Replace detected_text2 with processed_text\ndf['detected_text2'] = df['processed_text']\n\n# Remove the processed_text column\ndf.drop(columns=['processed_text'], inplace=True)\n\n# Now, let's create df_final by copying the required columns\ndf_final = pd.DataFrame()\ndf_final['index'] = df['index']  # Copy the 'index' column\ndf_final['entity_value'] = df['detected_text2']  # Rename 'processed_text' to 'entity_value'\n\n# Save to a new CSV file\noutput_file = '/kaggle/working/processed_output.csv'  # Corrected path\ndf_final.to_csv(output_file, index=False)\n\n# Show the first few rows of df_final\ndf_final.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:47:03.732785Z","iopub.execute_input":"2024-09-15T18:47:03.733548Z","iopub.status.idle":"2024-09-15T18:47:03.766710Z","shell.execute_reply.started":"2024-09-15T18:47:03.733478Z","shell.execute_reply":"2024-09-15T18:47:03.765539Z"},"trusted":true},"execution_count":290,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3356738012.py:23: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_subset['processed_text'] = df_subset.apply(lambda row: process_detected_text(row['entity_name'], row['detected_text2']), axis=1)\n/tmp/ipykernel_36/3356738012.py:35: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_subset['processed_text'] = df_subset.apply(fill_null_with_mode, axis=1)\n/tmp/ipykernel_36/3356738012.py:38: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_subset['detected_text2'] = df_subset['processed_text']\n/tmp/ipykernel_36/3356738012.py:41: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_subset.drop(columns=['processed_text'], inplace=True)\n","output_type":"stream"},{"execution_count":290,"output_type":"execute_result","data":{"text/plain":"   index    entity_value\n0      0                \n1      1   30 centimeter\n2      2                \n3      3   10 centimeter\n4      4   10 centimeter","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>entity_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>30 centimeter</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>10 centimeter</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>10 centimeter</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}